{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Charlotte Donald.docx ---\n",
      "\"Full Name\",\"Email ID\",\"Github Portfolio\",\"LinkedIn ID\",\"Employment Details\",\"Technical Skills\",\"Soft Skills\"\n",
      "\"Charlotte Donald\",\"CDonald@uk.ey.com\",\"\",\"\",\"\",\"Audit, IFRS 17, SOX, PCAOB, Financial Reporting, Insurance, Financial Services, Risk Management, Project Management, Client Money Audit, CASS 5, Financial Analysis, Data Analytics\",\"Communication, Leadership, Team Management, Time Management, Problem Solving, Client Relationship Management, Presentation, Event Organisation\"\n",
      "--- Umang Purwar RESUME-de.pdf ---\n",
      "\"Full Name\",\"Email ID\",\"Github Portfolio\",\"LinkedIn ID\",\"Employment Details\",\"Technical Skills\",\"Soft Skills\"\n",
      "\"Umang Purwar\",\"umangpurwar03@gmail.com\",\"\",\"https://www.linkedin.com/\",\"JR. DATA SCIENTIST | INNODATATICS | HYDERABAD, INDIA | DEC /2023 - PRESENT, DATA  SCIENCE INTERN | INNODATATICS | HYDERABAD, INDIA | APRIL /2023 - DEC /2023\",\"MLops, Artificial Intelligence, Machine Learning,  ETL, Computer Vision, Web scrapping, NLP, Large Language model, Data Analysis, Data Visualization, Neural Networks, Python, SQL, MS EXCEL, AWS, PowerBI, TensorFlow, Keras, PyTorch, NumPy, Pandas, Scikit -learn, OpenCV, statsmodels, Mage-AI ETL tool, NLU, LLM, Deep Learning, Transfer Learning, FIASS, CNN, YOLO, OCR, Image processing techniques\",\"\"\n",
      "Combined CSV file 'combined_employee_data.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import io\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a .docx file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import docx\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = []\n",
    "        for para in doc.paragraphs:\n",
    "            text.append(para.text)\n",
    "        return '\\n'.join(text)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to extract text from {docx_path}: {e}\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a .pdf file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from PyPDF2 import PdfReader\n",
    "        pdf_text = []\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                pdf_text.append(page.extract_text())\n",
    "        return '\\n'.join(pdf_text)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to extract text from {pdf_path}: {e}\")\n",
    "\n",
    "def extract_text_from_resume(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a resume file (.docx or .pdf).\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.docx'):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
    "\n",
    "def extract_text_from_resumes_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Extracts text from all resume files (.docx or .pdf) in a folder.\n",
    "    \"\"\"\n",
    "    resumes_text = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.docx') or filename.endswith('.pdf'):\n",
    "            try:\n",
    "                text = extract_text_from_resume(file_path)\n",
    "                resumes_text[filename] = text\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to extract text from {filename}: {e}\")\n",
    "    return resumes_text\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'data'\n",
    "resumes_text = extract_text_from_resumes_in_folder(folder_path)\n",
    "all_rows = []\n",
    "\n",
    "for filename, text in resumes_text.items():\n",
    "    print(f\"--- {filename} ---\")\n",
    "    # Define a template for the prompt\n",
    "    prompt_template = f'''\n",
    "        You are an AI bot designed to act as a professional for parsing resumes.\n",
    "        You are given with resume and your job is to extract the following information from the resume just that dont give additional text in the begining and end just this info:\n",
    "        1. full name\n",
    "        2. email id\n",
    "        3. github portfolio\n",
    "        4. linkedin id\n",
    "        5. employment details\n",
    "        6. technical skills\n",
    "        7. soft skills\n",
    "        Give the extracted information in csv format only\n",
    "        and this is resume{text} and dont add additional text in begining and end just extract csv and give complete information i dont want such line also\n",
    "        Here is the extracted information in CSV format:\n",
    "        '''\n",
    "    \n",
    "    client = Groq(\n",
    "        api_key=\"api key\",\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_template,\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "\n",
    "    response_content = chat_completion.choices[0].message.content\n",
    "    print(response_content)\n",
    "    # Use io.StringIO to treat the string as a file-like object\n",
    "    data_io = io.StringIO(response_content.strip())\n",
    "\n",
    "    # Read the data using csv.DictReader\n",
    "    reader = csv.DictReader(data_io, delimiter=',')\n",
    "    rows = list(reader)\n",
    "\n",
    "    # Extend the list of all rows with current rows\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "# Specify the path where you want to save the combined CSV file\n",
    "csv_file = 'combined_employee_data.csv'\n",
    "\n",
    "# Write all accumulated data to the CSV file using csv.DictWriter\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = [\"Full Name\", \"Email ID\", \"Github Portfolio\", \"LinkedIn ID\", \"Employment Details\", \"Technical Skills\", \"Soft Skills\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(f\"Combined CSV file '{csv_file}' has been created successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
